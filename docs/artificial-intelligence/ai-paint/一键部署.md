:::note
随着越来越多的人追上"AI绘图"这一热潮，Stable Diffusion 的受欢迎程度继续爆炸式增长。

作为模型公开且效果极佳的扩散模型Stable Diffusion是CompVis研究团队上个月(8月底)发布的。该模型使用 LAION 5B 数据集的子集进行训练，包括用于初始训练的高分辨率子集和用于后续各种开发者提升"美学"孕育出来的的各种针对性模型。
:::

## Stable-Diffusion-WEBUI

仓库地址：https://github.com/AUTOMATIC1111/stable-diffusion-webui

一键启动

```shell
./webui.sh
```

安装部署会花费较久时间（建议走下代理，否则git clone会非常慢）

```python title=lanch.py
def setGitProxy():
    run('git config --global http.proxy 127.0.0.1:7890')
    run('git config --global httpx.proxy 127.0.0.1:7890')


def prepare_environment():
...
setGitProxy()
...
```

搭建完成，我们可以通过浏览器访问到下面的界面：

![](https://oss.kinda.info/image/202302242213211.png)

通过调节不同参数可以生成不同效果，我这里根据自己的使用理解进行一些说明，希望对用户有帮助。

访问内容后分为几个大的模块;

- txt2img --- 标准的文字生成图像；
- img2img --- 根据图像成文范本、结合文字生成图像；
- Extras --- 优化(清晰、扩展)图像；
- PNG Info --- 图像基本信息
- Checkpoint Merger --- 模型合并
- Textual inversion --- 训练模型对于某种图像风格
- Settings --- 默认参数修改

## txt2img部分介绍

### 内容输入部分：

prompt 该部分主要就是对于图像进行描述，有内容风格等信息进行描述。后面的画板可以一些随机的风格、下面箭头是之前任务的参数；

Negative prompt 这个主要是提供给模型，我不想要什么样的风格；特别对于图上出现多个人的情况，就可以通过2girls等信息进行消除；

### 优化方法部分：

Sampling Steps diffusion model 生成图片的迭代步数，每多一次迭代都会给 AI 更多的机会去比对 prompt 和 当前结果，去调整图片。更高的步数需要花费更多的计算时间，也相对更贵。但不一定意味着更好的结果。当然迭代步数不足（少于 50）肯定会降低结果的图像质量；

Sampling method 扩散去噪算法的采样模式，会带来不一样的效果，ddim 和 pms(plms) 的结果差异会很大，很多人还会使用euler，具体没有系统测试；

Width、Height 图像长宽，可以通过send to extras 进行扩大，所以这里不建议设置太大[显存小的特别注意]；

Restore faces 优化面部，绘制面部图像特别注意；

Tiling 生成一个可以平铺的图像；

Highres. fix 使用两个步骤的过程进行生成，以较小的分辨率创建图像，然后在不改变构图的情况下改进其中的细节，选择该部分会有两个新的参数 Scale latent 在潜空间中对图像进行缩放。另一种方法是从潜在的表象中产生完整的图像，将其升级，然后将其移回潜在的空间。Denoising strength 决定算法对图像内容的保留程度。在0处，什么都不会改变，而在1处，你会得到一个不相关的图像；

Batch count、 Batch size 都是生成几张图，前者计算时间长，后者需要显存大；

CFG Scale 分类器自由引导尺度——图像与提示符的一致程度——越低的值产生越有创意的结果；

Seed 种子数，只要中子数一样，参数一致、模型一样图像就能重新；

## img2img部分介绍

这部分参数很多与txt2img类似，这里主要说明一下不同部分；

### 内容输入部分：

这里主要增加的是要模仿的图片，可以是手绘的、也可以是类似的；

其他文字信息类似，这里依然是描述越准确越好；

对于其中参数主要是图像是否要保存相同尺寸：

Just resize、 Crop and resize、 Resize and fill 这三种模式保证图输出效果，因为下面会有新的尺寸，是填充还是性对应缩放；

### 调整部分

这部分大部分参数与上面一致，主要新增加的是：

Denoising strength 与原图一致性的程度，一般大于0.7出来的都是新效果，小于0.3基本就会原图缝缝补补；

### Extras部分介绍

该部分主要将图像进行优化，其中很多方法的模型使用的时候会自动下载，很容易下载失败导致报错。

图片导入，也可以通过其他模块中的send to extras直接使用；

下面相关参数主要是对于图像的优化等工作，具体使用大家可以自己测试。

GFPGAN visibility 主要就是对于图像清晰度进行优化，例如下图：

其他参数使用不多，这里不做过多介绍。

### PNG Info部分介绍

该部分主要说明图像大小等信息。

后面的几个模块基本是调整模型何如何训练新的prompt的，这里就不做过多说明。