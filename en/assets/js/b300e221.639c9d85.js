"use strict";(self.webpackChunkalndaly_github_io=self.webpackChunkalndaly_github_io||[]).push([[1908],{1850:(e,o,n)=>{n.r(o),n.d(o,{assets:()=>c,contentTitle:()=>a,default:()=>d,frontMatter:()=>l,metadata:()=>t,toc:()=>s});const t=JSON.parse('{"id":"artificial-intelligence/yolov8/yovov8\u7ed3\u5408opencv","title":"yolov8\u7ed3\u5408opencv\u5b9e\u65f6\u68c0\u6d4b\u7269\u4f53\u5e76\u4e14\u505a\u51fa\u81ea\u5b9a\u4e49\u54cd\u5e94","description":"","source":"@site/docs/artificial-intelligence/yolov8/yovov8\u7ed3\u5408opencv.md","sourceDirName":"artificial-intelligence/yolov8","slug":"/artificial-intelligence/yolov8/yovov8\u7ed3\u5408opencv","permalink":"/en/docs/artificial-intelligence/yolov8/yovov8\u7ed3\u5408opencv","draft":false,"unlisted":false,"editUrl":"https://github.com/Alndaly/alndaly.github.io/tree/main/packages/create-docusaurus/templates/shared/docs/artificial-intelligence/yolov8/yovov8\u7ed3\u5408opencv.md","tags":[],"version":"current","lastUpdatedAt":1742396220000,"frontMatter":{"title":"yolov8\u7ed3\u5408opencv\u5b9e\u65f6\u68c0\u6d4b\u7269\u4f53\u5e76\u4e14\u505a\u51fa\u81ea\u5b9a\u4e49\u54cd\u5e94"},"sidebar":"ai","previous":{"title":"mac\u4f7f\u7528GPU\u7684\u4e00\u4e9b\u95ee\u9898","permalink":"/en/docs/artificial-intelligence/tensorflow/mac\u4f7f\u7528GPU\u7684\u4e00\u4e9b\u95ee\u9898"},"next":{"title":"yolov8\u81ea\u5b9a\u4e49\u8bc6\u522b\u7269\u4f53","permalink":"/en/docs/artificial-intelligence/yolov8/\u81ea\u5b9a\u4e49\u8bc6\u522b\u7269\u4f53"}}');var i=n(5105),r=n(3881);const l={title:"yolov8\u7ed3\u5408opencv\u5b9e\u65f6\u68c0\u6d4b\u7269\u4f53\u5e76\u4e14\u505a\u51fa\u81ea\u5b9a\u4e49\u54cd\u5e94"},a=void 0,c={},s=[];function m(e){const o={code:"code",pre:"pre",...(0,r.R)(),...e.components};return(0,i.jsx)(o.pre,{children:(0,i.jsx)(o.code,{className:"language-python",children:"import cv2\nimport torch\nfrom ultralytics import YOLO\nfrom ultralytics.yolo.utils.plotting import Annotator\nfrom transformers import pipeline\n\n# Create a new YOLO model from scratch\nmodel = YOLO('yolov8n.yaml')\n\n# Load a pretrained YOLO model (recommended for training)\nmodel = YOLO('yolov8n.pt')\n\n# Train the model using the 'coco128.yaml' dataset for 3 epochs\nmodel.train(data='coco128.yaml', epochs=3)\n\ncapture = cv2.VideoCapture(0)\n\ndef do_something():\n    ...\n\nwhile(True):\n    # \u83b7\u53d6\u4e00\u5e27\n    ret, image = capture.read()\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    annotator = Annotator(image)\n    results = model(image, stream=False, verbose=False)\n    for item in results:\n        person_code = 0.0\n        # \u5224\u65ad\u662f\u5426\u5b58\u5728\u4eba\n        if(person_code in item.boxes.cls.tolist()):\n            print(\"\u68c0\u6d4b\u5230\u4eba\u51fa\u73b0\")\n            print(\"\u4f4d\u7f6e: {}\".format(item.boxes.boxes[item.boxes.cls.tolist().index(person_code)]))\n            print(\"\u53ef\u4fe1\u5ea6: {}\".format(item.boxes.conf.tolist()[item.boxes.cls.tolist().index(person_code)]))\n            annotator.box_label(item.boxes.xyxy[item.boxes.cls.tolist().index(person_code)], f\"person {item.boxes.conf.tolist()[item.boxes.cls.tolist().index(person_code)]}\")\n            # \u6b64\u5904\u53ef\u4ee5\u589e\u52a0\u81ea\u5b9a\u4e49\u64cd\u4f5c\n            do_something()\n\n    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n    cv2.imshow('frame', image)\n    if cv2.waitKey(1) == ord('q'):\n        break\n"})})}function d(e={}){const{wrapper:o}={...(0,r.R)(),...e.components};return o?(0,i.jsx)(o,{...e,children:(0,i.jsx)(m,{...e})}):m(e)}},3881:(e,o,n)=>{n.d(o,{R:()=>l,x:()=>a});var t=n(8101);const i={},r=t.createContext(i);function l(e){const o=t.useContext(r);return t.useMemo((function(){return"function"==typeof e?e(o):{...o,...e}}),[o,e])}function a(e){let o;return o=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),t.createElement(r.Provider,{value:o},e.children)}}}]);